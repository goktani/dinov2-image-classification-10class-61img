# DINOv2 Image Classification - 10 Classes, 61 Images Each

Transfer learning and fine-tuning of a DINOv2 Vision Transformer model on a small custom dataset with 10 classes and 61 images per class using PyTorch and timm.

---

## Overview

This repository demonstrates how to use self-supervised vision transformer models—in particular, **DINOv2**—for custom image classification tasks on small datasets. By leveraging the power of pretrained architectures, you can achieve strong results even with limited data and compute resources.

Key features:
- Uses **DINOv2** via Hugging Face’s timm library
- Dataset: 10 classes, 61 images per class (custom folder format)
- Automated splitting into training and validation sets
- Data augmentation for improved generalizability
- Freeze all layers except the classifier head (only head is fine-tuned)
- Early stopping to prevent overfitting
- Best checkpoint saving

---

## File Structure

```
├── dinov2class10img61.py           # Main python training script
├── dinov2class10img61.ipynb        # Colab/Jupyter notebook version
├── label_names.json                # Label index to class name mapping
├── datasetv3/                      # Original unsplit dataset (10 folders, each 61 images)
├── datasetv3_train/                # Training split (autogenerated)
├── datasetv3_val/                  # Validation split (autogenerated)
├── best_dinov2_head_class10_img61.pth # Saved model checkpoint (best validation accuracy)
├── test_images/                    # Example images for model testing
├── test_imagesv0/                  # Additional test images
```

---

## Dataset Format

- Each class should have its own folder (e.g., `cat/`, `dog/`, ...), with 61 images per folder.
- The script automatically splits `datasetv3/` into training and validation sets (`datasetv3_train/`, `datasetv3_val/`).

```
datasetv3/
  ├── class_1/
  │     ├── img001.jpg
  │     ├── img002.jpg
  │     └── ...
  ├── class_2/
  │     └── ...
  └── ...
```

---

## Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/dinov2-image-classification-10class-61img.git
cd dinov2-image-classification-10class-61img
```

### 2. Prepare Your Dataset

- Place your images in the `datasetv3/` folder, ensuring each class has its own subfolder and 61 images per class.

### 3. Install Requirements

- Recommended: [Google Colab](https://colab.research.google.com/) (for easy access to `google.colab` and GPU)
- Otherwise, in your local Python 3.8+ environment:

```bash
pip install torch torchvision timm scikit-learn
```

### 4. Run Training

- If using Colab, open `dinov2class10img61.ipynb`
- Locally, on CPU/GPU:

```bash
python dinov2class10img61.py
```

- The script will:
    - Split the dataset into train/val
    - Augment data
    - Fine-tune the DINOv2 model (only classification head)
    - Save the best checkpoint as `best_dinov2_head_class10_img61.pth`

---

## Model & Training Pipeline

- **Model:** DINOv2 Vision Transformer (`vit_base_patch14_dinov2.lvd142m`)
- **Fine-tuning:** Only the classifier head (final linear layer) is trained; all backbone weights are frozen.
- **Optimizer:** Adam (`lr=0.002`)
- **Loss:** CrossEntropyLoss
- **Batch size:** 4 (suitable for small datasets)
- **Early stopping:** After 5 epochs with no improvement in validation accuracy
- **Augmentation:** Random resized crop, horizontal flip, color jitter, normalization

---

## Inference

To perform inference on new images using the best model:

```python
import torch
from torchvision import transforms
from PIL import Image
import timm

# Load model and weights
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=False, num_classes=10)
model.load_state_dict(torch.load('best_dinov2_head_class10_img61.pth', map_location=device))
model = model.to(device)
model.eval()

# Preprocess your image
transform = transforms.Compose([
    transforms.Resize((518, 518)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

img = Image.open('test_images/example.jpg')
input_tensor = transform(img).unsqueeze(0).to(device)

with torch.no_grad():
    output = model(input_tensor)
    pred_label = output.argmax(dim=1).item()

# Optional: Map label index to class name using label_names.json
import json
with open('label_names.json', 'r') as f:
    labels = json.load(f)
print('Predicted label:', labels[str(pred_label)])
```

---

## Customization

- **Change number of classes:** Adjust `num_classes` in the code and replace `datasetv3/` accordingly.
- **Change augmentation:** Edit `transform_train` and `transform_val` in the script.
- **Change patience or epochs:** Modify `patience` and `epochs` variables.

---

## Results

The best model checkpoint is saved as `best_dinov2_head_class10_img61.pth`. Model performance per epoch (accuracy/loss) will be printed to the console during training.

---

## Credits

- [DINOv2: OpenViT pretraining by Meta AI Research](https://github.com/facebookresearch/dinov2)
- [timm - PyTorch Image Models](https://github.com/huggingface/pytorch-image-models)
- [PyTorch](https://pytorch.org/)

---

## License

MIT License. Please check the respective license of DINOv2 and timm for pretrained weights.

---

## Contact

For questions, issues, or feature suggestions, please use the repository’s Issues page or contact [34goktan60@gmail.com].

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNNaBFj3wL2e6b+bku0Pjma"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"V_qnpA4D7OFD","executionInfo":{"status":"ok","timestamp":1753874194184,"user_tz":-180,"elapsed":9768,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}}},"outputs":[],"source":["# Gerekirse: !pip install torch torchvision\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","import os"]},{"cell_type":"code","source":["# Eğer Google Drive'daysa:\n","from google.colab import drive\n","drive.mount('/content/drive')\n","DATA_DIR = '/content/drive/MyDrive/Dinov2Demo/datasetv3'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lt54k1-F8ToG","executionInfo":{"status":"ok","timestamp":1753876566242,"user_tz":-180,"elapsed":2659,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}},"outputId":"746c32b0-7963-43e2-eeff-a409edd8aa49"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import shutil\n","import os\n","\n","def split_dataset(dataset_root, train_ratio=0.8):\n","    # Tüm resimleri ve sınıfları belirle\n","    classes = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]\n","    train_root = f\"{dataset_root}_train\"\n","    val_root = f\"{dataset_root}_val\"\n","    os.makedirs(train_root, exist_ok=True)\n","    os.makedirs(val_root, exist_ok=True)\n","\n","    for cls in classes:\n","        imgs = os.listdir(os.path.join(dataset_root, cls))\n","        train_imgs, val_imgs = train_test_split(imgs, train_size=train_ratio, random_state=42)\n","        os.makedirs(os.path.join(train_root, cls), exist_ok=True)\n","        os.makedirs(os.path.join(val_root, cls), exist_ok=True)\n","        for i in train_imgs:\n","            shutil.copy(os.path.join(dataset_root, cls, i), os.path.join(train_root, cls, i))\n","        for i in val_imgs:\n","            shutil.copy(os.path.join(dataset_root, cls, i), os.path.join(val_root, cls, i))\n","    return train_root, val_root\n","\n","train_dir, val_dir = split_dataset(DATA_DIR)\n","print(train_dir, val_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bc7S40X78c2-","executionInfo":{"status":"ok","timestamp":1753874204288,"user_tz":-180,"elapsed":8041,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}},"outputId":"b22a3f77-7e22-4da2-d407-98a05599978d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Dinov2Demo/datasetv3_train /content/drive/MyDrive/Dinov2Demo/datasetv3_val\n"]}]},{"cell_type":"code","source":["# Augmentation\n","transform_train = transforms.Compose([\n","    transforms.RandomResizedCrop(518), # Changed to 518\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","\n","transform_val = transforms.Compose([\n","    transforms.Resize((518, 518)), # Changed to 518\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","\n","train_ds = datasets.ImageFolder(train_dir, transform=transform_train)\n","val_ds = datasets.ImageFolder(val_dir, transform=transform_val)\n","\n","# Batch size küçük! Çünkü dataset küçük!\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\n","val_loader = torch.utils.data.DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=2)\n","\n","print(f'Train samples: {len(train_ds)}')\n","print(f'Validation samples: {len(val_ds)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kj4qkPyI8int","executionInfo":{"status":"ok","timestamp":1753874204326,"user_tz":-180,"elapsed":18,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}},"outputId":"0548577c-fa47-4fde-dd68-e5ad5b859a7e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 482\n","Validation samples: 128\n"]}]},{"cell_type":"code","source":["# HuggingFace ile DINOv2 yükleme (bu notebook için Huggingface ve timm ile kolay)\n","!pip install timm\n","\n","import timm\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Check available DINOv2 models in timm:\n","print(timm.list_models(\"*dinov2*\", pretrained=True))\n","# Use a recognized model name, for example: 'dinov2_vitb14'\n","model = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=True, num_classes=10)\n","model = model.to(device)\n","\n","# Sadece son katmanı eğit\n","for param in model.parameters():\n","    param.requires_grad = False\n","for param in model.head.parameters():\n","    param.requires_grad = True  # Sadece head\n","\n","optimizer = optim.Adam(model.head.parameters(), lr=0.002)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkG4v0bD8mYl","executionInfo":{"status":"ok","timestamp":1753874212599,"user_tz":-180,"elapsed":8271,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}},"outputId":"53d43137-9c07-4fc0-d34a-8c54b38ce59e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.34.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.7.14)\n","['vit_base_patch14_dinov2.lvd142m', 'vit_base_patch14_reg4_dinov2.lvd142m', 'vit_giant_patch14_dinov2.lvd142m', 'vit_giant_patch14_reg4_dinov2.lvd142m', 'vit_large_patch14_dinov2.lvd142m', 'vit_large_patch14_reg4_dinov2.lvd142m', 'vit_small_patch14_dinov2.lvd142m', 'vit_small_patch14_reg4_dinov2.lvd142m']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","patience = 5\n","best_acc = 0.0\n","epochs = 30\n","trigger_times = 0\n","\n","for epoch in range(epochs):\n","    model.train()\n","    for images, labels in train_loader:\n","        images = images.to(device); labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    correct, total = 0, 0\n","    val_losses = []\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device); labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_losses.append(loss.item())\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","    val_acc = correct / total\n","    print(f\"Epoch {epoch+1}: val acc: {val_acc:.3f}, val_loss: {np.mean(val_losses):.4f}\")\n","\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save(model.state_dict(), 'best_dinov2_head_class10_img61.pth')\n","        trigger_times = 0\n","    else:\n","        trigger_times += 1\n","        if trigger_times >= patience:\n","            print(\"Early stopping! No improvement for\", patience, \"epochs.\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZV1YCiXE8xzl","executionInfo":{"status":"ok","timestamp":1753874616551,"user_tz":-180,"elapsed":403953,"user":{"displayName":"Göktan İren","userId":"05123232311365943132"}},"outputId":"3e7786bf-e95c-44fa-eea7-ead252229d80"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: val acc: 0.992, val_loss: 0.0396\n","Epoch 2: val acc: 1.000, val_loss: 0.0264\n","Epoch 3: val acc: 1.000, val_loss: 0.0150\n","Epoch 4: val acc: 0.977, val_loss: 0.0465\n","Epoch 5: val acc: 1.000, val_loss: 0.0049\n","Epoch 6: val acc: 1.000, val_loss: 0.0048\n","Epoch 7: val acc: 0.984, val_loss: 0.0389\n","Early stopping! No improvement for 5 epochs.\n"]}]}]}